import os
import numpy as np
from dotenv import load_dotenv
import google.generativeai as genai
from chromadb import PersistentClient
from rank_bm25 import BM25Okapi # ğŸ‘ˆ í‚¤ì›Œë“œ ê²€ìƒ‰(BM25) ë¼ì´ë¸ŒëŸ¬ë¦¬

# ============================================
# 1. í™˜ê²½ ì„¤ì •
# ============================================
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    raise ValueError("GEMINI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

genai.configure(api_key=api_key)

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CHROMA_DB_PATH = os.path.join(BASE_DIR, "chroma_db")
COLLECTION_NAME = "txt_collection"

EMBEDDING_MODEL = "models/text-embedding-004"
GENERATION_MODEL = "gemini-2.5-flash"

# ============================================
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ============================================
def get_query_embedding(query: str):
    try:
        result = genai.embed_content(
            model=EMBEDDING_MODEL,
            content=query,
            task_type="retrieval_query",
        )
        return result["embedding"]
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ì˜¤ë¥˜: {e}")
        return None

def simple_tokenize(text):
    """ê°„ë‹¨í•œ ë„ì–´ì“°ê¸° ê¸°ë°˜ í† í¬ë‚˜ì´ì € (í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° ì—†ì´ ì‚¬ìš©)"""
    return text.lower().split()

# ============================================
# 3. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (Vector + Keyword)
# ============================================
def hybrid_search(query, collection, k=10):
    """
    ChromaDB(ë²¡í„°)ì™€ BM25(í‚¤ì›Œë“œ)ë¥¼ ê²°í•©í•˜ì—¬ ìµœê³ ì˜ ë¬¸ì„œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    """
    print("\n---  í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œì‘ (Vector + BM25) ---")
    
    # 1. DBì— ìˆëŠ” ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸° (BM25 ì¸ë±ì‹±ìš©)
    # (ë¬¸ì„œ ì–‘ì´ ìˆ˜ë§Œ ê°œê°€ ì•„ë‹ˆë©´ ë§¤ë²ˆ ë¡œë“œí•´ë„ ë¹ ë¦…ë‹ˆë‹¤)
    all_docs_data = collection.get() 
    all_docs = all_docs_data['documents']
    all_ids = all_docs_data['ids']
    
    if not all_docs:
        print(" DBê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return []

    # -------------------------------------------------------
    # A. BM25 (í‚¤ì›Œë“œ ê²€ìƒ‰) ì ìˆ˜ ê³„ì‚°
    # -------------------------------------------------------
    tokenized_corpus = [simple_tokenize(doc) for doc in all_docs]
    bm25 = BM25Okapi(tokenized_corpus)
    
    tokenized_query = simple_tokenize(query)
    bm25_scores = bm25.get_scores(tokenized_query)
    
    # ì ìˆ˜ ì •ê·œí™” (0~1 ì‚¬ì´ë¡œ ë§ì¶¤)
    if np.max(bm25_scores) > 0:
        bm25_scores = bm25_scores / np.max(bm25_scores)
    
    # -------------------------------------------------------
    # B. Vector (ì˜ë¯¸ ê²€ìƒ‰) ì ìˆ˜ ê³„ì‚°
    # -------------------------------------------------------
    query_embedding = get_query_embedding(query)
    if not query_embedding: return []

    # ChromaDBì—ì„œ ì „ì²´ ë¬¸ì„œì™€ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ê¸° ì–´ë ¤ìš°ë¯€ë¡œ,
    # ì—¬ê¸°ì„œëŠ” ê²€ìƒ‰ëœ Top-Kë§Œ ì“°ëŠ” ê²Œ ì•„ë‹ˆë¼, 
    # BM25ê°€ ì°¾ì€ ë¬¸ì„œë“¤ì— ëŒ€í•´ ë²¡í„° ìœ ì‚¬ë„ë¥¼ ê²€ì¦í•˜ê±°ë‚˜ ê²°í•©í•˜ëŠ” ë°©ì‹ì„ ì”ë‹ˆë‹¤.
    # í•˜ì§€ë§Œ êµ¬í˜„ì˜ í¸ì˜ë¥¼ ìœ„í•´ Chromaì—ì„œ ë„“ê²Œ(Top-100) ê°€ì ¸ì™€ì„œ ì„ê² ìŠµë‹ˆë‹¤.
    
    vector_results = collection.query(
        query_embeddings=[query_embedding],
        n_results=len(all_docs), # ì „ì²´ ë¬¸ì„œ ëŒ€ìƒ (ì†Œê·œëª¨ë¼ ê°€ëŠ¥)
    )
    
    # ë²¡í„° ê±°ë¦¬(Distance)ë¥¼ ìœ ì‚¬ë„(Score)ë¡œ ë³€í™˜ (ê±°ë¦¬ê°€ 0ì´ë©´ ì ìˆ˜ 1)
    # Chroma DistanceëŠ” ë³´í†µ L2(ìœ í´ë¦¬ë“œ)ë‚˜ Cosine ê±°ë¦¬
    distances = vector_results['distances'][0]
    vector_ids = vector_results['ids'][0]
    
    # ID:Score ë”•ì…”ë„ˆë¦¬ ìƒì„±
    vector_score_map = {}
    max_dist = max(distances) if distances else 1
    for doc_id, dist in zip(vector_ids, distances):
        # ê±°ë¦¬ê°€ ê°€ê¹Œìš¸ìˆ˜ë¡(ì‘ì„ìˆ˜ë¡) ì ìˆ˜ê°€ ë†’ì•„ì•¼ í•¨
        score = 1 - (dist / (max_dist + 0.0001)) 
        vector_score_map[doc_id] = score

    # -------------------------------------------------------
    # C. ì ìˆ˜ ê²°í•© (Weighted Sum)
    # -------------------------------------------------------
    final_scores = []
    
    # ê°€ì¤‘ì¹˜ ì„¤ì • (í‚¤ì›Œë“œ ì¤‘ìš”í•˜ë©´ alphaë¥¼ ë†’ì„)
    # ì—¬ê¸°ì„œëŠ” í‚¤ì›Œë“œ(0.6) + ì˜ë¯¸(0.4) ì •ë„ë¡œ ì„¤ì •
    alpha = 0.6 
    
    for i, doc_id in enumerate(all_ids):
        v_score = vector_score_map.get(doc_id, 0)
        k_score = bm25_scores[i]
        
        # ìµœì¢… ì ìˆ˜ = (í‚¤ì›Œë“œì ìˆ˜ * 0.6) + (ë²¡í„°ì ìˆ˜ * 0.4)
        total_score = (k_score * alpha) + (v_score * (1 - alpha))
        
        # [ê°•ì˜ëª…] íƒœê·¸ê°€ ìˆìœ¼ë©´ ê°€ì‚°ì  (ë©”íƒ€ë°ì´í„° ì¸ì ì…˜ íš¨ê³¼ ê·¹ëŒ€í™”)
        if query.split()[0] in all_docs[i]: # ë‹¨ìˆœ ì²´í¬
             total_score += 0.1

        final_scores.append((total_score, all_docs[i]))

    # ì ìˆ˜ìˆœ ì •ë ¬
    final_scores.sort(key=lambda x: x[0], reverse=True)
    
    # ìƒìœ„ Kê°œ ë°˜í™˜
    return [doc for score, doc in final_scores[:k]]

# ============================================
# 4. ë©”ì¸ ì‹¤í–‰ ë¡œì§
# ============================================
def run_rag(query):
    if not os.path.exists(CHROMA_DB_PATH):
        return "DBê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € /build APIë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."

    client = PersistentClient(path=CHROMA_DB_PATH)
    collection = client.get_collection(COLLECTION_NAME)

    # 1. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰ (Top 7)
    top_docs = hybrid_search(query, collection, k=7)
    
    if not top_docs:
        return "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

    # --- Gemini ë‹µë³€ ìƒì„± ---
    context = "\n\n".join(top_docs)
    
    prompt = f"""
    ë‹¹ì‹ ì€ ìˆ˜ê°•ì‹ ì²­ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. 
    [ê´€ë ¨ ë¬¸ì„œ]ë¥¼ ë³´ê³  ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

    [ê´€ë ¨ ë¬¸ì„œ]
    {context}

    [ì§ˆë¬¸]
    {query}

    [ë‹µë³€ ì§€ì¹¨]
    1. êµìˆ˜ë‹˜ ì„±í•¨, ê³¼ëª©ëª… ë“± ê³ ìœ ëª…ì‚¬ëŠ” ë¬¸ì„œì— ìˆëŠ” ê·¸ëŒ€ë¡œ ì •í™•íˆ ë§í•˜ì„¸ìš”.
    2. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  í•˜ì„¸ìš”.
    3. ì¶œì²˜ê°€ ë˜ëŠ” ê°•ì˜ëª…ì„ í•¨ê»˜ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
    """

    try:
        model = genai.GenerativeModel(GENERATION_MODEL)
        resp = model.generate_content(prompt)
        return resp.text   
    except Exception as e:
        return f"Gemini API ì˜¤ë¥˜: {e}"
